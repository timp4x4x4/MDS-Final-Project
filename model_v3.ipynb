{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfdf69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 1: 導入套件和設定（改進版，抑制警告）\n",
    "# ===========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 抑制警告\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "# 檢查 GPU 支援（簡化版）\n",
    "def check_gpu_support():\n",
    "    \"\"\"檢查 LightGBM GPU 支援\"\"\"\n",
    "    try:\n",
    "        # 抑制 GPU 編譯警告\n",
    "        import subprocess\n",
    "        import sys\n",
    "        \n",
    "        # 創建測試數據\n",
    "        test_data = lgb.Dataset(\n",
    "            np.random.rand(100, 10), \n",
    "            label=np.random.randint(0, 2, 100)\n",
    "        )\n",
    "        test_params = {\n",
    "            'device_type': 'gpu',\n",
    "            'objective': 'binary',\n",
    "            'verbose': -1,\n",
    "            'force_row_wise': True\n",
    "        }\n",
    "        \n",
    "        # 靜默測試\n",
    "        with open(os.devnull, 'w') as devnull:\n",
    "            old_stdout = sys.stdout\n",
    "            sys.stdout = devnull\n",
    "            try:\n",
    "                lgb.train(test_params, test_data, num_boost_round=1)\n",
    "                result = True\n",
    "            except:\n",
    "                result = False\n",
    "            finally:\n",
    "                sys.stdout = old_stdout\n",
    "        \n",
    "        return result\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# 檢查環境\n",
    "print(\"環境檢查:\")\n",
    "print(f\"LightGBM: {lgb.__version__}\")\n",
    "\n",
    "# 檢查 GPU\n",
    "gpu_available = check_gpu_support()\n",
    "if gpu_available:\n",
    "    print(\"✅ GPU 加速可用！\")\n",
    "    device_type = 'gpu'\n",
    "else:\n",
    "    print(\"❌ GPU 加速不可用，將使用 CPU\")\n",
    "    device_type = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30044c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 2: 載入和準備資料\n",
    "# ===========================\n",
    "print(\"\\n載入資料...\")\n",
    "file_path = 'us-accidents/US_Accidents_March23.csv'\n",
    "\n",
    "# 載入資料\n",
    "df = pd.read_csv(file_path)\n",
    "print(f\"原始資料大小: {df.shape}\")\n",
    "\n",
    "# 顯示目標變數分布\n",
    "print(\"\\n目標變數分布:\")\n",
    "severity_counts = df['Severity'].value_counts().sort_index()\n",
    "for sev, count in severity_counts.items():\n",
    "    print(f\"Severity {sev}: {count:,} ({count/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8448503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 3: 進階特徵工程和預處理（改進版）\n",
    "# ===========================\n",
    "print(\"\\n準備特徵（進階預處理）...\")\n",
    "\n",
    "# 處理時間特徵\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'])\n",
    "df['Hour'] = df['Start_Time'].dt.hour\n",
    "df['DayOfWeek'] = df['Start_Time'].dt.dayofweek\n",
    "df['Month'] = df['Start_Time'].dt.month\n",
    "df['DayOfMonth'] = df['Start_Time'].dt.day\n",
    "df['Year'] = df['Start_Time'].dt.year\n",
    "\n",
    "# 新增時間特徵\n",
    "df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(int)\n",
    "df['IsRushHour'] = df['Hour'].apply(lambda x: 1 if (6 <= x <= 9) or (16 <= x <= 19) else 0)\n",
    "df['Season'] = df['Month'].apply(lambda x: (x%12 + 3)//3)  # 1=冬, 2=春, 3=夏, 4=秋\n",
    "\n",
    "# 選擇特徵\n",
    "numeric_features = [\n",
    "    'Start_Lat', 'Start_Lng', \n",
    "    'Distance(mi)', 'Temperature(F)', 'Wind_Chill(F)', \n",
    "    'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', \n",
    "    'Wind_Speed(mph)', 'Precipitation(in)',\n",
    "    'Hour', 'DayOfWeek', 'Month', 'DayOfMonth', 'Year',\n",
    "    'IsWeekend', 'IsRushHour', 'Season'\n",
    "]\n",
    "\n",
    "boolean_features = [\n",
    "    'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', \n",
    "    'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', \n",
    "    'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', \n",
    "    'Astronomical_Twilight'\n",
    "]\n",
    "\n",
    "# 合併所有特徵\n",
    "all_features = numeric_features + boolean_features + categorical_features\n",
    "existing_features = [col for col in all_features if col in df.columns]\n",
    "\n",
    "# 準備特徵矩陣\n",
    "X = df[existing_features].copy()\n",
    "\n",
    "# ===========================\n",
    "# 資料清理和異常值處理\n",
    "# ===========================\n",
    "print(\"\\n進行資料清理...\")\n",
    "\n",
    "# 1. 處理異常值（使用 IQR 方法）\n",
    "def handle_outliers(df, columns, method='clip'):\n",
    "    \"\"\"處理異常值\"\"\"\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 3 * IQR\n",
    "            upper_bound = Q3 + 3 * IQR\n",
    "            \n",
    "            if method == 'clip':\n",
    "                df[col] = df[col].clip(lower_bound, upper_bound)\n",
    "            elif method == 'remove':\n",
    "                df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 處理數值特徵的異常值（只處理天氣相關特徵）\n",
    "weather_features = ['Temperature(F)', 'Humidity(%)', 'Pressure(in)', \n",
    "                   'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)']\n",
    "X = handle_outliers(X, weather_features, method='clip')\n",
    "\n",
    "# 2. 處理缺失值（更智能的填充）\n",
    "print(\"處理缺失值...\")\n",
    "\n",
    "# 對於數值特徵，使用中位數填充\n",
    "for col in numeric_features:\n",
    "    if col in X.columns:\n",
    "        median_val = X[col].median()\n",
    "        X[col] = X[col].fillna(median_val)\n",
    "\n",
    "# 對於布林特徵，轉換並填充為 0\n",
    "for col in boolean_features:\n",
    "    if col in X.columns:\n",
    "        X[col] = X[col].map({True: 1, False: 0}).fillna(0)\n",
    "\n",
    "# 對於類別特徵，使用眾數填充\n",
    "for col in categorical_features:\n",
    "    if col in X.columns:\n",
    "        mode_val = X[col].mode()[0] if len(X[col].mode()) > 0 else 'Unknown'\n",
    "        X[col] = X[col].fillna(mode_val)\n",
    "        X[col] = pd.Categorical(X[col]).codes\n",
    "\n",
    "# 3. 特徵縮放（可選，LightGBM 不太需要，但有助於穩定性）\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "numeric_cols = [col for col in numeric_features if col in X.columns]\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "\n",
    "# 保存 scaler 以供預測時使用\n",
    "joblib.dump(scaler, './model_output/feature_scaler.pkl')\n",
    "\n",
    "# ===========================\n",
    "# 處理類別不平衡\n",
    "# ===========================\n",
    "print(\"\\n處理類別不平衡...\")\n",
    "\n",
    "# 準備目標變數\n",
    "y = df['Severity'].values - 1  # 轉換為 0-3\n",
    "\n",
    "# 顯示原始分布\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(\"原始類別分布:\")\n",
    "for cls, cnt in zip(unique, counts):\n",
    "    print(f\"  Severity {cls+1}: {cnt:,} ({cnt/len(y)*100:.2f}%)\")\n",
    "\n",
    "# 計算類別權重\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "\n",
    "# 轉換為 LightGBM 格式\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "print(\"\\n計算的類別權重:\")\n",
    "for cls, weight in class_weight_dict.items():\n",
    "    print(f\"  Severity {cls+1}: {weight:.4f}\")\n",
    "\n",
    "# 可選：使用 SMOTE 進行過採樣（僅用於訓練集）\n",
    "use_smote = False  # 設為 True 以啟用 SMOTE\n",
    "\n",
    "if use_smote:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    print(\"\\n應用 SMOTE 過採樣...\")\n",
    "    smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    print(f\"過採樣後大小: {X_resampled.shape}\")\n",
    "else:\n",
    "    X_resampled, y_resampled = X, y\n",
    "\n",
    "print(f\"\\n最終特徵矩陣大小: {X_resampled.shape}\")\n",
    "\n",
    "# 儲存特徵名稱\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "\n",
    "# ===== 把最終資料交給後續 Cell 4 / 5 使用 =====\n",
    "if isinstance(X_resampled, np.ndarray):            # 若啟用 SMOTE 會變成 ndarray\n",
    "    X_final = pd.DataFrame(X_resampled, columns=feature_names)\n",
    "else:\n",
    "    X_final = X_resampled.copy()                   # 仍為 DataFrame\n",
    "\n",
    "y_final = y_resampled.astype(int)                  # 0‒3 的 ndarray\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dce068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 4: 使用 K-Fold 交叉驗證評估 LightGBM（修正版，強化 early stopping）\n",
    "# ===========================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"訓練 LightGBM 模型（使用全部數據，{device_type.upper()} 模式）\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# LightGBM 參數\n",
    "lgb_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 4,\n",
    "    'metric': 'multi_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 63,\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'reg_alpha': 0.01,\n",
    "    'reg_lambda': 0.01,\n",
    "    'min_split_gain': 0.01,\n",
    "    'min_child_weight': 1,\n",
    "    'min_child_samples': 20,\n",
    "    'verbose': -1,\n",
    "    'random_state': 42,\n",
    "    'extra_trees': True,\n",
    "    'path_smooth': 0.2,\n",
    "    'force_row_wise': True,  # 避免警告\n",
    "    'device_type': device_type,\n",
    "}\n",
    "\n",
    "# 如果使用 GPU，添加 GPU 特定參數\n",
    "if device_type == 'gpu':\n",
    "    lgb_params.update({\n",
    "        'max_bin': 63,\n",
    "        'gpu_use_dp': False,\n",
    "        'num_threads': 0,\n",
    "    })\n",
    "else:\n",
    "    lgb_params['n_jobs'] = -1\n",
    "\n",
    "# K-Fold 交叉驗證\n",
    "print(\"\\n進行 5-Fold 交叉驗證...\")\n",
    "print(f\"資料集大小: {len(X):,} 筆\")\n",
    "print(\"使用 Early Stopping（patience=200）\")\n",
    "print(\"最大迭代次數: 10,000（如果需要可跑整晚）\\n\")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = {\n",
    "    'accuracy': [],\n",
    "    'f1': [],\n",
    "    'balanced_accuracy': [],\n",
    "    'best_iterations': [],\n",
    "    'training_times': []\n",
    "}\n",
    "\n",
    "total_start_time = time.time()\n",
    "\n",
    "# 改進的進度回調類別\n",
    "class ProgressCallback:\n",
    "    def __init__(self, fold_num, print_freq=100):\n",
    "        self.fold_num = fold_num\n",
    "        self.print_freq = print_freq\n",
    "        self.start_time = time.time()\n",
    "        self.last_print_time = time.time()\n",
    "        self.best_score = float('inf')\n",
    "        self.best_iteration = 0\n",
    "        self.no_improve_rounds = 0\n",
    "        \n",
    "    def __call__(self, env):\n",
    "        # 確保 env 有 iteration 屬性\n",
    "        if not hasattr(env, 'iteration'):\n",
    "            return\n",
    "            \n",
    "        iteration = env.iteration + 1\n",
    "        \n",
    "        # 只在特定頻率印出\n",
    "        if iteration % self.print_freq == 0 or iteration == 1:\n",
    "            current_time = time.time()\n",
    "            elapsed = current_time - self.start_time\n",
    "            speed = iteration / elapsed if elapsed > 0 else 0\n",
    "            \n",
    "            # 獲取驗證分數\n",
    "            if hasattr(env, 'evaluation_result_list') and env.evaluation_result_list:\n",
    "                # 處理不同版本的 LightGBM\n",
    "                result = env.evaluation_result_list[-1]\n",
    "                if isinstance(result, tuple):\n",
    "                    current_score = result[2] if len(result) >= 3 else result[1]\n",
    "                else:\n",
    "                    current_score = self.best_score\n",
    "                \n",
    "                # 更新最佳分數\n",
    "                if current_score < self.best_score:\n",
    "                    self.best_score = current_score\n",
    "                    self.best_iteration = iteration\n",
    "                    self.no_improve_rounds = 0\n",
    "                else:\n",
    "                    self.no_improve_rounds = iteration - self.best_iteration\n",
    "                \n",
    "                print(f\"  [Fold {self.fold_num}] Iter {iteration:5d} | \"\n",
    "                      f\"Valid Loss: {current_score:.6f} | \"\n",
    "                      f\"Best: {self.best_score:.6f} @ {self.best_iteration} | \"\n",
    "                      f\"No improve: {self.no_improve_rounds} | \"\n",
    "                      f\"Speed: {speed:.1f} it/s\")\n",
    "            else:\n",
    "                print(f\"  [Fold {self.fold_num}] Iter {iteration:5d} | \"\n",
    "                      f\"Speed: {speed:.1f} it/s\")\n",
    "\n",
    "# 訓練每個 fold\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(X_final, y_final)):\n",
    "    fold_start_time = time.time()\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Fold {fold + 1}/5\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"訓練集: {len(train_idx):,} 筆\")\n",
    "    print(f\"驗證集: {len(val_idx):,} 筆\")\n",
    "    \n",
    "    # 分割數據\n",
    "    if isinstance(X_final, pd.DataFrame):\n",
    "        X_train_fold = X_final.iloc[train_idx]\n",
    "        X_val_fold = X_final.iloc[val_idx]\n",
    "    else:\n",
    "        X_train_fold = X_final[train_idx]\n",
    "        X_val_fold = X_final[val_idx]\n",
    "    \n",
    "    y_train_fold = y_final[train_idx]\n",
    "    y_val_fold = y_final[val_idx]\n",
    "    \n",
    "    # 創建數據集\n",
    "    train_data = lgb.Dataset(X_train_fold, label=y_train_fold)\n",
    "    valid_data = lgb.Dataset(X_val_fold, label=y_val_fold, reference=train_data)\n",
    "    \n",
    "    # 訓練模型\n",
    "    print(f\"\\n開始訓練（{device_type.upper()}）...\")\n",
    "    print(\"設定: num_boost_round=10000, early_stopping_rounds=200\")\n",
    "    \n",
    "    try:\n",
    "        # 使用自定義 callback 和內建 early stopping\n",
    "        callbacks = [\n",
    "            lgb.early_stopping(stopping_rounds=200, verbose=False),\n",
    "            lgb.log_evaluation(0),  # 0 表示不印出預設 log\n",
    "            ProgressCallback(fold + 1, print_freq=100)\n",
    "        ]\n",
    "        \n",
    "        model_fold = lgb.train(\n",
    "            lgb_params,\n",
    "            train_data,\n",
    "            valid_sets=[valid_data],\n",
    "            valid_names=['valid'],\n",
    "            num_boost_round=10000,  # 設定很大，讓 early stopping 決定何時停止\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n訓練錯誤: {str(e)}\")\n",
    "        print(\"嘗試使用簡化的訓練方式...\")\n",
    "        \n",
    "        # 備用訓練方式\n",
    "        model_fold = lgb.train(\n",
    "            lgb_params,\n",
    "            train_data,\n",
    "            valid_sets=[valid_data],\n",
    "            num_boost_round=2000,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=200),\n",
    "                lgb.log_evaluation(100)\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    # 預測和評估\n",
    "    y_pred = model_fold.predict(X_val_fold, num_iteration=model_fold.best_iteration)\n",
    "    y_pred_class = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    acc = accuracy_score(y_val_fold, y_pred_class)\n",
    "    f1 = f1_score(y_val_fold, y_pred_class, average='weighted')\n",
    "    balanced_acc = balanced_accuracy_score(y_val_fold, y_pred_class)\n",
    "    \n",
    "    cv_scores['accuracy'].append(acc)\n",
    "    cv_scores['f1'].append(f1)\n",
    "    cv_scores['balanced_accuracy'].append(balanced_acc)\n",
    "    cv_scores['best_iterations'].append(model_fold.best_iteration)\n",
    "    \n",
    "    fold_time = time.time() - fold_start_time\n",
    "    cv_scores['training_times'].append(fold_time)\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1} 完成！\")\n",
    "    print(f\"  最佳迭代次數: {model_fold.best_iteration}\")\n",
    "    print(f\"  準確率: {acc:.4f}\")\n",
    "    print(f\"  F1分數: {f1:.4f}\")\n",
    "    print(f\"  平衡準確率: {balanced_acc:.4f}\")\n",
    "    print(f\"  訓練時間: {fold_time/60:.2f} 分鐘\")\n",
    "    \n",
    "    # 估計剩餘時間\n",
    "    if fold < 4:\n",
    "        avg_fold_time = np.mean(cv_scores['training_times'])\n",
    "        remaining_folds = 4 - fold\n",
    "        eta_minutes = (avg_fold_time * remaining_folds) / 60\n",
    "        print(f\"\\n預估剩餘時間: {eta_minutes:.1f} 分鐘\")\n",
    "    \n",
    "    # 清理記憶體\n",
    "    del model_fold, train_data, valid_data\n",
    "    gc.collect()\n",
    "\n",
    "# 顯示交叉驗證結果\n",
    "total_cv_time = time.time() - total_start_time\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"交叉驗證結果:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"使用設備: {device_type.upper()}\")\n",
    "print(f\"平均準確率: {np.mean(cv_scores['accuracy']):.4f} (±{np.std(cv_scores['accuracy']):.4f})\")\n",
    "print(f\"平均F1分數: {np.mean(cv_scores['f1']):.4f} (±{np.std(cv_scores['f1']):.4f})\")\n",
    "print(f\"平均平衡準確率: {np.mean(cv_scores['balanced_accuracy']):.4f} (±{np.std(cv_scores['balanced_accuracy']):.4f})\")\n",
    "print(f\"平均最佳迭代次數: {np.mean(cv_scores['best_iterations']):.0f} (±{np.std(cv_scores['best_iterations']):.0f})\")\n",
    "print(f\"平均每個 Fold 時間: {np.mean(cv_scores['training_times'])/60:.2f} 分鐘\")\n",
    "print(f\"\\n總交叉驗證時間: {total_cv_time/60:.2f} 分鐘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e69d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 5: 使用全部數據訓練最終模型（強化 early stopping）\n",
    "# ===========================\n",
    "lgb_params.update({\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 4,\n",
    "    'learning_rate': 0.15,  # 關鍵調整\n",
    "    'num_leaves': 31,       # 減少複雜度\n",
    "    'max_depth': 6,\n",
    "    'class_weight': 'balanced',  # 關鍵調整\n",
    "    'device_type': device_type,\n",
    "})\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"使用全部數據訓練最終模型\")\n",
    "print(\"=\"*60)\n",
    "print(f\"訓練集大小: {len(X_final):,} 筆\")\n",
    "print(f\"使用設備: {device_type.upper()}\")\n",
    "\n",
    "# 基於 CV 結果調整訓練參數\n",
    "suggested_rounds = int(np.mean(cv_scores['best_iterations']) * 1.5)\n",
    "max_rounds = max(20000, suggested_rounds * 2)  # 至少 20000 輪\n",
    "\n",
    "print(f\"建議迭代次數: {suggested_rounds}\")\n",
    "print(f\"最大迭代次數: {max_rounds} (可跑整晚)\")\n",
    "print(f\"Early stopping: 500 輪無改善即停止\")\n",
    "print(\"\\n如果想要更長時間的訓練，模型會自動使用 early stopping 在最佳點停止\")\n",
    "\n",
    "# 準備全部數據\n",
    "if isinstance(X_final, pd.DataFrame):\n",
    "    train_data_full = lgb.Dataset(X_final, label=y_final)\n",
    "else:\n",
    "    train_data_full = lgb.Dataset(X_final, label=y_final)\n",
    "\n",
    "# 最終訓練進度回調\n",
    "class FinalTrainingCallback:\n",
    "    def __init__(self, print_freq=200):\n",
    "        self.print_freq = print_freq\n",
    "        self.start_time = time.time()\n",
    "        self.best_score = float('inf')\n",
    "        self.best_iteration = 0\n",
    "        \n",
    "    def __call__(self, env):\n",
    "        if not hasattr(env, 'iteration'):\n",
    "            return\n",
    "            \n",
    "        iteration = env.iteration + 1\n",
    "        \n",
    "        if iteration % self.print_freq == 0 or iteration == 1:\n",
    "            elapsed = time.time() - self.start_time\n",
    "            speed = iteration / elapsed if elapsed > 0 else 0\n",
    "            eta = (env.end_iteration - iteration) / speed if speed > 0 else 0\n",
    "            \n",
    "            # 獲取訓練分數\n",
    "            if hasattr(env, 'evaluation_result_list') and env.evaluation_result_list:\n",
    "                result = env.evaluation_result_list[0]\n",
    "                if isinstance(result, tuple):\n",
    "                    current_score = result[2] if len(result) >= 3 else result[1]\n",
    "                    \n",
    "                    if current_score < self.best_score:\n",
    "                        self.best_score = current_score\n",
    "                        self.best_iteration = iteration\n",
    "                    \n",
    "                    no_improve = iteration - self.best_iteration\n",
    "                    \n",
    "                    print(f\"  Iteration {iteration:5d}/{env.end_iteration} | \"\n",
    "                          f\"Train Loss: {current_score:.6f} | \"\n",
    "                          f\"Best: {self.best_score:.6f} @ {self.best_iteration} | \"\n",
    "                          f\"No improve: {no_improve} | \"\n",
    "                          f\"Speed: {speed:.1f} it/s | \"\n",
    "                          f\"ETA: {eta/60:.1f} min\")\n",
    "\n",
    "# 訓練最終模型\n",
    "print(\"\\n開始訓練...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# 分割一小部分作為驗證集以監控訓練\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(\n",
    "    X_final, y_final, test_size=0.1, random_state=42, stratify=y_final\n",
    ")\n",
    "\n",
    "train_data_final = lgb.Dataset(X_train_final, label=y_train_final)\n",
    "valid_data_final = lgb.Dataset(X_val_final, label=y_val_final, reference=train_data_final)\n",
    "\n",
    "try:\n",
    "    final_model = lgb.train(\n",
    "        lgb_params,\n",
    "        train_data_final,\n",
    "        valid_sets=[train_data_final, valid_data_final],\n",
    "        valid_names=['train', 'valid'],\n",
    "        num_boost_round=max_rounds,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=500, verbose=True),\n",
    "            lgb.log_evaluation(0),\n",
    "            FinalTrainingCallback(print_freq=200)\n",
    "        ]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"訓練錯誤: {str(e)}\")\n",
    "    print(\"使用備用方法...\")\n",
    "    \n",
    "    final_model = lgb.train(\n",
    "        lgb_params,\n",
    "        train_data_final,\n",
    "        valid_sets=[valid_data_final],\n",
    "        num_boost_round=max_rounds,\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=500),\n",
    "            lgb.log_evaluation(200)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "print(f\"\\n訓練完成！\")\n",
    "print(f\"訓練時間: {train_time/60:.2f} 分鐘\")\n",
    "print(f\"最終迭代次數: {final_model.best_iteration}\")\n",
    "print(f\"訓練速度: {final_model.best_iteration/train_time:.1f} 迭代/秒\")\n",
    "\n",
    "# 保存模型\n",
    "model_path = './model_output/final_lgb_model.pkl'\n",
    "joblib.dump(final_model, model_path)\n",
    "print(f\"模型已保存至: {model_path}\")\n",
    "\n",
    "# 在驗證集上的最終評估\n",
    "y_pred_final = final_model.predict(X_val_final, num_iteration=final_model.best_iteration)\n",
    "y_pred_class_final = np.argmax(y_pred_final, axis=1)\n",
    "\n",
    "print(f\"\\n驗證集最終性能:\")\n",
    "print(f\"準確率: {accuracy_score(y_val_final, y_pred_class_final):.4f}\")\n",
    "print(f\"F1分數: {f1_score(y_val_final, y_pred_class_final, average='weighted'):.4f}\")\n",
    "print(f\"平衡準確率: {balanced_accuracy_score(y_val_final, y_pred_class_final):.4f}\")\n",
    "\n",
    "# 顯示總體時間統計\n",
    "total_time = time.time() - total_start_time\n",
    "print(f\"\\n總執行時間（含交叉驗證）: {total_time/60:.2f} 分鐘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 6: 特徵重要性分析\n",
    "# ===========================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"特徵重要性分析\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "feature_importance = final_model.feature_importance(importance_type='gain')\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 重要特徵:\")\n",
    "for idx, row in feature_importance_df.head(15).iterrows():\n",
    "    print(f\"{row['feature']:<25} {row['importance']:>10.2f}\")\n",
    "\n",
    "# 視覺化特徵重要性\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance_df.head(20)\n",
    "plt.barh(range(len(top_features)), top_features['importance'], color='lightblue')\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('重要性分數')\n",
    "plt.title('LightGBM 特徵重要性 (Top 20)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./model_output/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 7: 創建未來時空預測系統\n",
    "# ===========================\n",
    "class AccidentPredictor:\n",
    "    \"\"\"事故預測系統，可以預測未來時空的事故風險\"\"\"\n",
    "    \n",
    "    def __init__(self, model, feature_names):\n",
    "        self.model = model\n",
    "        self.feature_names = feature_names\n",
    "        \n",
    "        # 載入歷史數據統計\n",
    "        self.load_historical_stats()\n",
    "    \n",
    "    def load_historical_stats(self):\n",
    "        \"\"\"載入歷史數據統計資訊\"\"\"\n",
    "        print(\"\\n載入歷史統計資訊...\")\n",
    "        \n",
    "        # 讀取數據來計算統計\n",
    "        df_stats = pd.read_csv(file_path, nrows=100000)\n",
    "        \n",
    "        # 計算各種統計值\n",
    "        self.lat_range = (df_stats['Start_Lat'].quantile(0.05), \n",
    "                         df_stats['Start_Lat'].quantile(0.95))\n",
    "        self.lng_range = (df_stats['Start_Lng'].quantile(0.05), \n",
    "                         df_stats['Start_Lng'].quantile(0.95))\n",
    "        \n",
    "        # 天氣條件的統計\n",
    "        self.weather_stats = {\n",
    "            'Temperature(F)': {\n",
    "                'mean': df_stats['Temperature(F)'].mean(),\n",
    "                'std': df_stats['Temperature(F)'].std()\n",
    "            },\n",
    "            'Humidity(%)': {\n",
    "                'mean': df_stats['Humidity(%)'].mean(),\n",
    "                'std': df_stats['Humidity(%)'].std()\n",
    "            },\n",
    "            'Pressure(in)': {\n",
    "                'mean': df_stats['Pressure(in)'].mean(),\n",
    "                'std': df_stats['Pressure(in)'].std()\n",
    "            },\n",
    "            'Visibility(mi)': {\n",
    "                'mean': df_stats['Visibility(mi)'].mean(),\n",
    "                'std': df_stats['Visibility(mi)'].std()\n",
    "            },\n",
    "            'Wind_Speed(mph)': {\n",
    "                'mean': df_stats['Wind_Speed(mph)'].mean(),\n",
    "                'std': df_stats['Wind_Speed(mph)'].std()\n",
    "            },\n",
    "            'Precipitation(in)': {\n",
    "                'mean': df_stats['Precipitation(in)'].mean(),\n",
    "                'std': df_stats['Precipitation(in)'].std()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 道路特徵的概率\n",
    "        self.road_feature_probs = {}\n",
    "        for feat in boolean_features:\n",
    "            if feat in df_stats.columns:\n",
    "                self.road_feature_probs[feat] = df_stats[feat].mean()\n",
    "        \n",
    "        print(\"統計資訊載入完成\")\n",
    "    \n",
    "    def generate_prediction_grid(self, \n",
    "                               start_date, \n",
    "                               end_date, \n",
    "                               lat_points=20, \n",
    "                               lng_points=20,\n",
    "                               hours_step=3,\n",
    "                               weather_scenario='normal'):\n",
    "        \"\"\"生成未來時空網格的預測\"\"\"\n",
    "        print(f\"\\n生成預測網格...\")\n",
    "        print(f\"日期範圍: {start_date.strftime('%Y-%m-%d')} 至 {end_date.strftime('%Y-%m-%d')}\")\n",
    "        print(f\"空間網格: {lat_points} x {lng_points}\")\n",
    "        print(f\"時間步長: {hours_step} 小時\")\n",
    "        print(f\"天氣場景: {weather_scenario}\")\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        # 生成時間序列\n",
    "        current_time = start_date\n",
    "        time_points = []\n",
    "        while current_time <= end_date:\n",
    "            time_points.append(current_time)\n",
    "            current_time += timedelta(hours=hours_step)\n",
    "        \n",
    "        # 生成空間網格\n",
    "        lats = np.linspace(self.lat_range[0], self.lat_range[1], lat_points)\n",
    "        lngs = np.linspace(self.lng_range[0], self.lng_range[1], lng_points)\n",
    "        \n",
    "        total_predictions = len(time_points) * lat_points * lng_points\n",
    "        print(f\"總預測點數: {total_predictions:,}\")\n",
    "        \n",
    "        # 批次處理\n",
    "        batch_size = 1000\n",
    "        batch_features = []\n",
    "        batch_info = []\n",
    "        processed = 0\n",
    "        \n",
    "        for t, time_point in enumerate(time_points):\n",
    "            # 時間特徵\n",
    "            hour = time_point.hour\n",
    "            day_of_week = time_point.weekday()\n",
    "            month = time_point.month\n",
    "            day_of_month = time_point.day\n",
    "            year = time_point.year\n",
    "            \n",
    "            # 根據時間和場景調整天氣\n",
    "            weather = self._get_weather_conditions(hour, month, weather_scenario)\n",
    "            \n",
    "            for lat in lats:\n",
    "                for lng in lngs:\n",
    "                    # 創建特徵向量\n",
    "                    features = self._create_feature_vector(\n",
    "                        lat, lng, hour, day_of_week, month, day_of_month, year, weather\n",
    "                    )\n",
    "                    \n",
    "                    batch_features.append(features)\n",
    "                    batch_info.append({\n",
    "                        'latitude': lat,\n",
    "                        'longitude': lng,\n",
    "                        'timestamp': time_point,\n",
    "                        'weather': weather\n",
    "                    })\n",
    "                    \n",
    "                    # 批次預測\n",
    "                    if len(batch_features) >= batch_size:\n",
    "                        self._process_batch(batch_features, batch_info, predictions)\n",
    "                        processed += len(batch_features)\n",
    "                        batch_features = []\n",
    "                        batch_info = []\n",
    "                        \n",
    "                        # 顯示進度\n",
    "                        if processed % 10000 == 0:\n",
    "                            progress = processed / total_predictions * 100\n",
    "                            print(f\"  進度: {progress:.1f}%\")\n",
    "        \n",
    "        # 處理剩餘的批次\n",
    "        if batch_features:\n",
    "            self._process_batch(batch_features, batch_info, predictions)\n",
    "        \n",
    "        print(\"預測完成！\")\n",
    "        return pd.DataFrame(predictions)\n",
    "    \n",
    "    def _get_weather_conditions(self, hour, month, scenario):\n",
    "        \"\"\"根據時間和場景生成天氣條件\"\"\"\n",
    "        weather = {}\n",
    "        \n",
    "        for condition, stats in self.weather_stats.items():\n",
    "            base_value = stats['mean']\n",
    "            std = stats['std']\n",
    "            \n",
    "            # 季節調整\n",
    "            if condition == 'Temperature(F)':\n",
    "                if month in [12, 1, 2]:  # 冬季\n",
    "                    base_value -= 20\n",
    "                elif month in [6, 7, 8]:  # 夏季\n",
    "                    base_value += 20\n",
    "                \n",
    "                # 時間調整\n",
    "                if hour >= 22 or hour <= 6:  # 夜間\n",
    "                    base_value -= 10\n",
    "            \n",
    "            # 場景調整\n",
    "            if scenario == 'bad':\n",
    "                if condition == 'Visibility(mi)':\n",
    "                    base_value *= 0.5\n",
    "                elif condition == 'Precipitation(in)':\n",
    "                    base_value = max(0.5, base_value * 3)\n",
    "                elif condition == 'Wind_Speed(mph)':\n",
    "                    base_value *= 1.5\n",
    "            elif scenario == 'good':\n",
    "                if condition == 'Visibility(mi)':\n",
    "                    base_value = min(10, base_value * 1.5)\n",
    "                elif condition == 'Precipitation(in)':\n",
    "                    base_value = 0\n",
    "                elif condition == 'Wind_Speed(mph)':\n",
    "                    base_value *= 0.7\n",
    "            \n",
    "            # 添加一些隨機變化\n",
    "            weather[condition] = max(0, base_value + np.random.normal(0, std * 0.1))\n",
    "        \n",
    "        return weather\n",
    "    \n",
    "    def _create_feature_vector(self, lat, lng, hour, dow, month, dom, year, weather):\n",
    "        \"\"\"創建特徵向量\"\"\"\n",
    "        features = np.zeros(len(self.feature_names))\n",
    "        \n",
    "        for i, feat_name in enumerate(self.feature_names):\n",
    "            if feat_name == 'Start_Lat':\n",
    "                features[i] = lat\n",
    "            elif feat_name == 'Start_Lng':\n",
    "                features[i] = lng\n",
    "            elif feat_name == 'Hour':\n",
    "                features[i] = hour\n",
    "            elif feat_name == 'DayOfWeek':\n",
    "                features[i] = dow\n",
    "            elif feat_name == 'Month':\n",
    "                features[i] = month\n",
    "            elif feat_name == 'DayOfMonth':\n",
    "                features[i] = dom\n",
    "            elif feat_name == 'Year':\n",
    "                features[i] = year\n",
    "            elif feat_name in weather:\n",
    "                features[i] = weather[feat_name]\n",
    "            elif feat_name in self.road_feature_probs:\n",
    "                features[i] = 1 if np.random.random() < self.road_feature_probs[feat_name] else 0\n",
    "            elif feat_name == 'Distance(mi)':\n",
    "                features[i] = np.random.exponential(2)\n",
    "            elif feat_name == 'Wind_Chill(F)':\n",
    "                # 根據溫度估算風寒\n",
    "                temp = weather.get('Temperature(F)', 70)\n",
    "                features[i] = temp - 5 if temp < 50 else temp\n",
    "            else:\n",
    "                features[i] = -999\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _process_batch(self, batch_features, batch_info, predictions):\n",
    "        \"\"\"批次處理預測\"\"\"\n",
    "        X_batch = np.array(batch_features)\n",
    "        \n",
    "        # 預測\n",
    "        pred_proba = self.model.predict(X_batch, num_iteration=self.model.best_iteration)\n",
    "        pred_class = np.argmax(pred_proba, axis=1)\n",
    "        \n",
    "        # 計算風險分數\n",
    "        risk_weights = np.array([0.1, 0.3, 0.6, 1.0])\n",
    "        risk_scores = np.sum(pred_proba * risk_weights, axis=1)\n",
    "        \n",
    "        # 整理結果\n",
    "        for i, (info, risk, severity, proba) in enumerate(zip(batch_info, risk_scores, pred_class, pred_proba)):\n",
    "            predictions.append({\n",
    "                'latitude': round(info['latitude'], 6),\n",
    "                'longitude': round(info['longitude'], 6),\n",
    "                'timestamp': info['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                'predicted_severity': int(severity + 1),\n",
    "                'risk_score': round(float(risk), 4),\n",
    "                'risk_category': self._get_risk_category(risk),\n",
    "                'hour': info['timestamp'].hour,\n",
    "                'day_of_week': info['timestamp'].weekday(),\n",
    "                'day_name': info['timestamp'].strftime('%A'),\n",
    "                'temperature': round(info['weather']['Temperature(F)'], 1),\n",
    "                'visibility': round(info['weather']['Visibility(mi)'], 1),\n",
    "                'precipitation': round(info['weather']['Precipitation(in)'], 2),\n",
    "                'humidity': round(info['weather']['Humidity(%)'], 1),\n",
    "                'wind_speed': round(info['weather']['Wind_Speed(mph)'], 1),\n",
    "                'severity_1_prob': round(float(proba[0]), 4),\n",
    "                'severity_2_prob': round(float(proba[1]), 4),\n",
    "                'severity_3_prob': round(float(proba[2]), 4),\n",
    "                'severity_4_prob': round(float(proba[3]), 4)\n",
    "            })\n",
    "    \n",
    "    def _get_risk_category(self, risk_score):\n",
    "        \"\"\"根據風險分數分類\"\"\"\n",
    "        if risk_score < 0.25:\n",
    "            return 'Low'\n",
    "        elif risk_score < 0.5:\n",
    "            return 'Medium'\n",
    "        elif risk_score < 0.75:\n",
    "            return 'High'\n",
    "        else:\n",
    "            return 'Very High'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f8beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 8: 生成未來預測\n",
    "# ===========================\n",
    "# 創建預測器\n",
    "predictor = AccidentPredictor(final_model, feature_names)\n",
    "\n",
    "# 設定預測參數\n",
    "start_date = datetime.now()\n",
    "end_date = start_date + timedelta(days=7)  # 預測未來7天\n",
    "\n",
    "# 生成三種天氣場景的預測\n",
    "scenarios = ['normal', 'bad', 'good']\n",
    "all_predictions = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(f\"\\n生成 {scenario} 天氣場景預測...\")\n",
    "    predictions = predictor.generate_prediction_grid(\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        lat_points=20,\n",
    "        lng_points=20,\n",
    "        hours_step=4,  # 每4小時一個預測\n",
    "        weather_scenario=scenario\n",
    "    )\n",
    "    predictions['weather_scenario'] = scenario\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "# 合併所有預測\n",
    "future_predictions = pd.concat(all_predictions, ignore_index=True)\n",
    "print(f\"\\n總預測數據量: {len(future_predictions):,}\")\n",
    "\n",
    "# 保存預測數據\n",
    "output_path = './model_output/future_predictions_kepler.csv'\n",
    "future_predictions.to_csv(output_path, index=False)\n",
    "print(f\"預測數據已保存至: {output_path}\")\n",
    "\n",
    "# 創建 GeoJSON\n",
    "features = []\n",
    "for idx, row in future_predictions.iterrows():\n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"geometry\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": [row['longitude'], row['latitude']]\n",
    "        },\n",
    "        \"properties\": {key: value for key, value in row.items() \n",
    "                      if key not in ['latitude', 'longitude']}\n",
    "    }\n",
    "    features.append(feature)\n",
    "\n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "\n",
    "geojson_path = './model_output/future_predictions_kepler.json'\n",
    "with open(geojson_path, 'w') as f:\n",
    "    json.dump(geojson, f)\n",
    "\n",
    "print(f\"GeoJSON 已保存至: {geojson_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef2c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 9: 創建預測摘要和視覺化\n",
    "# ===========================\n",
    "# 預測摘要統計\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"預測摘要統計\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 按天氣場景統計\n",
    "scenario_stats = future_predictions.groupby('weather_scenario').agg({\n",
    "    'risk_score': ['mean', 'std', 'min', 'max'],\n",
    "    'predicted_severity': 'mean'\n",
    "})\n",
    "print(\"\\n各天氣場景統計:\")\n",
    "print(scenario_stats)\n",
    "\n",
    "# 按時間統計\n",
    "time_stats = future_predictions.groupby('hour')['risk_score'].mean()\n",
    "print(\"\\n高風險時段 (Top 5):\")\n",
    "print(time_stats.nlargest(5))\n",
    "\n",
    "# 風險分布\n",
    "risk_dist = future_predictions['risk_category'].value_counts()\n",
    "print(\"\\n風險類別分布:\")\n",
    "print(risk_dist)\n",
    "\n",
    "# 視覺化\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. 風險分數時間分布\n",
    "ax1 = axes[0, 0]\n",
    "for scenario in scenarios:\n",
    "    data = future_predictions[future_predictions['weather_scenario'] == scenario]\n",
    "    hourly_risk = data.groupby('hour')['risk_score'].mean()\n",
    "    ax1.plot(hourly_risk.index, hourly_risk.values, marker='o', label=scenario)\n",
    "ax1.set_xlabel('小時')\n",
    "ax1.set_ylabel('平均風險分數')\n",
    "ax1.set_title('24小時風險分布')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. 風險類別餅圖\n",
    "ax2 = axes[0, 1]\n",
    "colors = {'Low': 'green', 'Medium': 'yellow', 'High': 'orange', 'Very High': 'red'}\n",
    "risk_counts = future_predictions['risk_category'].value_counts()\n",
    "ax2.pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%',\n",
    "        colors=[colors[cat] for cat in risk_counts.index])\n",
    "ax2.set_title('風險類別分布')\n",
    "\n",
    "# 3. 天氣場景比較\n",
    "ax3 = axes[1, 0]\n",
    "scenario_comparison = future_predictions.groupby(['weather_scenario', 'risk_category']).size().unstack()\n",
    "scenario_comparison.plot(kind='bar', stacked=True, ax=ax3, \n",
    "                         color=['green', 'yellow', 'orange', 'red'])\n",
    "ax3.set_xlabel('天氣場景')\n",
    "ax3.set_ylabel('預測數量')\n",
    "ax3.set_title('不同天氣場景的風險分布')\n",
    "ax3.legend(title='風險類別')\n",
    "\n",
    "# 4. 嚴重程度預測分布\n",
    "ax4 = axes[1, 1]\n",
    "severity_dist = future_predictions.groupby(['weather_scenario', 'predicted_severity']).size().unstack()\n",
    "severity_dist.plot(kind='bar', ax=ax4)\n",
    "ax4.set_xlabel('天氣場景')\n",
    "ax4.set_ylabel('預測數量')\n",
    "ax4.set_title('預測嚴重程度分布')\n",
    "ax4.legend(title='嚴重程度', labels=['Level 1', 'Level 2', 'Level 3', 'Level 4'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./model_output/prediction_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8466d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Cell 10: 保存模型資訊\n",
    "# ===========================\n",
    "model_info = {\n",
    "    \"model_type\": \"LightGBM\",\n",
    "    \"training_info\": {\n",
    "        \"timestamp\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"data_size\": len(X),\n",
    "        \"feature_count\": len(feature_names),\n",
    "        \"training_time_minutes\": train_time/60\n",
    "    },\n",
    "    \"performance\": {\n",
    "        \"cv_accuracy\": f\"{np.mean(cv_scores['accuracy']):.4f} (±{np.std(cv_scores['accuracy']):.4f})\",\n",
    "        \"cv_f1_score\": f\"{np.mean(cv_scores['f1']):.4f} (±{np.std(cv_scores['f1']):.4f})\",\n",
    "        \"cv_balanced_accuracy\": f\"{np.mean(cv_scores['balanced_accuracy']):.4f} (±{np.std(cv_scores['balanced_accuracy']):.4f})\"\n",
    "    },\n",
    "    \"features\": feature_names,\n",
    "    \"hyperparameters\": lgb_params,\n",
    "    \"prediction_info\": {\n",
    "        \"total_predictions\": len(future_predictions),\n",
    "        \"date_range\": f\"{start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\",\n",
    "        \"scenarios\": scenarios,\n",
    "        \"spatial_resolution\": f\"{20} x {20} grid points\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('./model_output/model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"完成！\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n產出檔案:\")\n",
    "print(\"1. final_lgb_model.pkl - 訓練好的模型\")\n",
    "print(\"2. future_predictions_kepler.csv - Kepler.gl CSV 格式\")\n",
    "print(\"3. future_predictions_kepler.json - Kepler.gl GeoJSON 格式\")\n",
    "print(\"4. feature_importance.png - 特徵重要性圖\")\n",
    "print(\"5. prediction_summary.png - 預測摘要圖\")\n",
    "print(\"6. model_info.json - 模型資訊\")\n",
    "print(\"\\n使用 Kepler.gl:\")\n",
    "print(\"1. 前往 https://kepler.gl/\")\n",
    "print(\"2. 上傳 CSV 或 JSON 檔案\")\n",
    "print(\"3. 使用時間滑塊查看風險演變\")\n",
    "print(\"4. 根據 weather_scenario 篩選不同天氣\")\n",
    "print(\"5. 使用 risk_score 創建熱力圖\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
